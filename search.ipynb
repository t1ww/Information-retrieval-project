{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Recipe Browser Project\n",
    "\n",
    "By `652115013 Narongchai Rongthong`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we load the data from parquet file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes data already loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check if recipes_df is already loaded\n",
    "if 'recipes_df' not in globals():\n",
    "    recipes_df = pd.read_parquet('resource/recipes.parquet')\n",
    "    print(f\"Loaded {len(recipes_df)} recipes.\")\n",
    "else:\n",
    "    print(\"Recipes data already loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"_Z9BSk2zcMuFD=-1LlAX\"),\n",
    "    ca_certs=\"~/http_ca.crt\"\n",
    ")\n",
    "\n",
    "if es_client.ping():\n",
    "    print(\"Connected to Elasticsearch\")\n",
    "else:\n",
    "    print(\"Elasticsearch connection failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can start indexing the data\n",
    "- applying fields we need\n",
    "    - id\n",
    "    - name\n",
    "    - ingredients\n",
    "    - instuctions\n",
    "\n",
    "For searching i want to join those together so its easier to find into `cleaned` \"search text\"\n",
    "\n",
    "along with extra cleaned name\n",
    "\n",
    "Through `stemming` and removing `stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Setup text cleaner\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Exclude specific stopwords\n",
    "important_stop_words =  {\"with\", \"and\"}\n",
    "custom_stopwords = set(stopwords.words('english')) - important_stop_words  \n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())  \n",
    "    filtered_tokens = [word for word in tokens if word not in custom_stopwords]  \n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]  \n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Additionally, since if we send very short query like `\"t\"` or `\"to\"` we'd get completely empty results\n",
    "instead we can make it try to show up something that matches their `ngrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18048\\2273960558.py:10: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=index_name, ignore=[400, 404])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index: recipes\n"
     ]
    },
    {
     "ename": "BulkIndexError",
     "evalue": "36 document(s) failed to index.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkIndexError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 182\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m doc\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Bulk index the sample documents\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[43mbulk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mes_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipes_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(recipes_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m recipes into Elasticsearch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:540\u001b[0m, in \u001b[0;36mbulk\u001b[1;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# make streaming_bulk yield successful results so we can count them\u001b[39;00m\n\u001b[0;32m    539\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myield_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ok, item \u001b[38;5;129;01min\u001b[39;00m streaming_bulk(\n\u001b[0;32m    541\u001b[0m     client, actions, ignore_status\u001b[38;5;241m=\u001b[39mignore_status, span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelpers.bulk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    542\u001b[0m ):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# go through request-response pairs and detect failures\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stats_only:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:453\u001b[0m, in \u001b[0;36mstreaming_bulk\u001b[1;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, retry_on_status, span_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(max_backoff, initial_backoff \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (attempt \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, (ok, info) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    454\u001b[0m         bulk_data,\n\u001b[0;32m    455\u001b[0m         _process_bulk_chunk(\n\u001b[0;32m    456\u001b[0m             client,\n\u001b[0;32m    457\u001b[0m             bulk_actions,\n\u001b[0;32m    458\u001b[0m             bulk_data,\n\u001b[0;32m    459\u001b[0m             otel_span,\n\u001b[0;32m    460\u001b[0m             raise_on_exception,\n\u001b[0;32m    461\u001b[0m             raise_on_error,\n\u001b[0;32m    462\u001b[0m             ignore_status,\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    465\u001b[0m         ),\n\u001b[0;32m    466\u001b[0m     ):\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[0;32m    468\u001b[0m             action, info \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mpopitem()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:359\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[1;34m(client, bulk_actions, bulk_data, otel_span, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _process_bulk_chunk_success(\n\u001b[0;32m    354\u001b[0m         resp\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    355\u001b[0m         bulk_data\u001b[38;5;241m=\u001b[39mbulk_data,\n\u001b[0;32m    356\u001b[0m         ignore_status\u001b[38;5;241m=\u001b[39mignore_status,\n\u001b[0;32m    357\u001b[0m         raise_on_error\u001b[38;5;241m=\u001b[39mraise_on_error,\n\u001b[0;32m    358\u001b[0m     )\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m gen\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:276\u001b[0m, in \u001b[0;36m_process_bulk_chunk_success\u001b[1;34m(resp, bulk_data, ignore_status, raise_on_error)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m ok, {op_type: item}\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BulkIndexError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m document(s) failed to index.\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors)\n",
      "\u001b[1;31mBulkIndexError\u001b[0m: 36 document(s) failed to index."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "# Define index name and sample size for development\n",
    "index_name = \"recipes\"\n",
    "sample_size = 100  # Set the sample size for testing (adjust as needed)\n",
    "\n",
    "# Delete the index if it already exists\n",
    "es_client.indices.delete(index=index_name, ignore=[400, 404])\n",
    "\n",
    "# Create the index with a mapping that uses an English analyzer\n",
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"ngram_tokenizer\": {\n",
    "                    \"type\": \"ngram\",\n",
    "                    \"min_gram\": 2,  # Minimum length of n-grams\n",
    "                    \"max_gram\": 3,  # Maximum length of n-grams\n",
    "                    \"token_chars\": [\"letter\", \"digit\"]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\n",
    "                    \"type\": \"english\"\n",
    "                },\n",
    "                \"ngram_analyzer\": {  # Add a custom n-gram analyzer\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"ngram_tokenizer\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"recipe_id\": {\"type\": \"keyword\"},\n",
    "            \"name\": { \n",
    "                \"type\": \"text\", \n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": { \n",
    "                    \"ngram\": {  # Add an n-gram variant of the name field\n",
    "                        \"type\": \"text\", \n",
    "                        \"analyzer\": \"ngram_analyzer\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"cleaned_name\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"author_name\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"recipe_category\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"description\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"ingredients\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"instructions\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"keywords\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"search_text\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"image_urls\": {\"type\": \"keyword\"},\n",
    "            # Time-related fields\n",
    "            \"cook_time\": {\"type\": \"text\"},\n",
    "            \"prep_time\": {\"type\": \"text\"},\n",
    "            \"total_time\": {\"type\": \"text\"},\n",
    "            # Nutritional content fields\n",
    "            \"calories\": {\"type\": \"float\"},\n",
    "            \"fat_content\": {\"type\": \"float\"},\n",
    "            \"cholesterol_content\": {\"type\": \"float\"},\n",
    "            \"carbohydrate_content\": {\"type\": \"float\"},\n",
    "            \"fiber_content\": {\"type\": \"float\"},\n",
    "            \"sugar_content\": {\"type\": \"float\"},\n",
    "            \"protein_content\": {\"type\": \"float\"},\n",
    "            \"recipe_servings\": {\"type\": \"float\"},\n",
    "            \"recipe_yield\": {\"type\": \"float\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the index\n",
    "es_client.indices.create(index=index_name, body=mapping)\n",
    "print(f\"Created index: {index_name}\")\n",
    "\n",
    "# Get a sample of the recipes for development (you can adjust sample size)\n",
    "recipes_sample = recipes_df.head(sample_size)\n",
    "\n",
    "# Prepare the documents for bulk indexing\n",
    "def generate_docs(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        # Main Informations\n",
    "        recipe_id = str(int(float(row.get('RecipeId', idx))))  # Ensures it's always an integer string\n",
    "        name = row.get('Name', '')\n",
    "        cleaned_name = clean_text(name)\n",
    "        author_name = row.get('AuthorName', '')\n",
    "        recipe_category = row.get('RecipeCategory', '')\n",
    "        description = row.get('Description', '')\n",
    "        ingredients = list(zip(row.get('RecipeIngredientParts', []), row.get('RecipeIngredientQuantities', [])))\n",
    "        instructions = row.get('RecipeInstructions', [])\n",
    "        keywords = row.get('Keywords', [])\n",
    "        \n",
    "        # Time\n",
    "        cook_time = row.get('CookTime', '')\n",
    "        prep_time = row.get('PrepTime', '')\n",
    "        total_time = row.get('TotalTime', '')\n",
    "        \n",
    "        # Nutritional Contents\n",
    "        calories = row.get('Calories', 0.0)\n",
    "        fat_content = row.get('FatContent', 0.0)\n",
    "        cholesterol_content = row.get('CholesterolContent', 0.0)\n",
    "        carbohydrate_content = row.get('CarbohydrateContent', 0.0)\n",
    "        fiber_content = row.get('FiberContent', 0.0)\n",
    "        sugar_content = row.get('SugarContent', 0.0)\n",
    "        protein_content = row.get('ProteinContent', 0.0)\n",
    "        recipe_servinges = row.get('RecipeServings', 0.0)\n",
    "        recipe_yield = row.get('RecipeYield', 0.0)\n",
    "        \n",
    "        # Construct the search text: cleaning and combining Name, Ingredients, and Instructions\n",
    "        # Clean ingredients and instructions by joining the parts and quantities, then applying clean_text\n",
    "        ingredients_text = \" \".join([f\"{ingredient} {quantity}\" for ingredient, quantity in ingredients])\n",
    "        instructions_text = \" \".join(instructions)\n",
    "\n",
    "        # Combine and clean everything\n",
    "        search_text = clean_text(\" \".join([name, ingredients_text, instructions_text]))\n",
    "        \n",
    "        # Handle image_url field\n",
    "        image_urls = row.get('Images', [])\n",
    "\n",
    "        doc = {\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": recipe_id,\n",
    "            \"_source\": {\n",
    "                \"recipe_id\": recipe_id,\n",
    "                \"name\": name,\n",
    "                \"cleaned_name\": cleaned_name,\n",
    "                \"author_name\": author_name,\n",
    "                \"description\": description,\n",
    "                \"ingredients\": ingredients,\n",
    "                \"instructions\": instructions,\n",
    "                \"keywords\": keywords,\n",
    "                \"search_text\": search_text,\n",
    "                \"image_urls\": image_urls\n",
    "            }\n",
    "        }\n",
    "        yield doc\n",
    "\n",
    "# Bulk index the sample documents\n",
    "bulk(es_client, generate_docs(recipes_sample))\n",
    "\n",
    "print(f\"Indexed {len(recipes_sample)} recipes into Elasticsearch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create user system for token and tracking for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dummy user authentication and storage.\n"
     ]
    }
   ],
   "source": [
    "# --- Dummy User & In-Memory Data for Auth, Bookmarks, and Folders ---\n",
    "\n",
    "# Dummy user database (for UC-001: Authentication)\n",
    "users = {\n",
    "    \"user1\": \"password1\",\n",
    "    \"user2\": \"password2\"\n",
    "}\n",
    "\n",
    "# In-memory storage\n",
    "sessions = {}  # token -> username\n",
    "user_bookmarks = {}  # username -> list of {recipe_id, rating}\n",
    "user_folders = {}   # username -> {folder_name: [recipe_ids]}\n",
    "\n",
    "import uuid\n",
    "\n",
    "def generate_token():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "print(\"Initialized dummy user authentication and storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create flask app to expose api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask API endpoints defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Flask API Endpoints ---\n",
    "from flask import Flask, request, jsonify\n",
    "import random\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, supports_credentials=True, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "# Development mode token (for easier development)\n",
    "DEV_TOKEN = \"dev\" \n",
    "\n",
    "def generate_token():\n",
    "    return str(random.randint(100000, 999999))\n",
    "\n",
    "# UC-001: User Authentication\n",
    "@app.route('/login', methods=['POST'])\n",
    "def login():\n",
    "    data = request.get_json()\n",
    "    username = data.get(\"username\")\n",
    "    password = data.get(\"password\")\n",
    "    if username in users and users[username] == password:\n",
    "        token = generate_token()\n",
    "        sessions[token] = username\n",
    "        return jsonify({\"message\": \"Login successful\", \"token\": token})\n",
    "    return jsonify({\"message\": \"Invalid credentials\"}), 401\n",
    "\n",
    "@app.route('/logout', methods=['POST'])\n",
    "def logout():\n",
    "    token = request.headers.get(\"Authorization\")\n",
    "    if token in sessions:\n",
    "        sessions.pop(token)\n",
    "        return jsonify({\"message\": \"Logout successful\"})\n",
    "    return jsonify({\"message\": \"Invalid token\"}), 401\n",
    "\n",
    "# Helper function to check authentication\n",
    "def is_authenticated(request):\n",
    "    token = request.headers.get(\"Authorization\")\n",
    "    return token == DEV_TOKEN or token in sessions\n",
    "\n",
    "# UC-002 & UC-003: Recipe Search Functionality & Display Results\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    \n",
    "    # Responds\n",
    "    query = request.args.get(\"query\", \"\")\n",
    "    cleaned_query = clean_text(query)\n",
    "    res = es_client.search(index=index_name, body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    { \"match\": { \"name\": { \"query\": query, \"boost\": 3 } } },  # No stemming (Best match)\n",
    "                    { \"match\": { \"name.ngram\": { \"query\": query, \"boost\": 2 } } },  # Partial match with n-grams\n",
    "                    { \"match\": { \"stemmed_name\": { \"query\": cleaned_query, \"boost\": 2 } } },  # Stemmed query\n",
    "                    { \"match\": { \"search_text\": { \"query\": cleaned_query, \"fuzziness\": \"AUTO\", \"boost\": 1 } } }  # Stemmed + Fuzzy\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    hits = res[\"hits\"][\"hits\"]\n",
    "    results = [\n",
    "        {\n",
    "            \"recipe_id\": hit[\"_source\"][\"recipe_id\"],\n",
    "            \"name\": hit[\"_source\"][\"name\"],\n",
    "            \"snippet\": hit[\"_source\"][\"instructions\"][:150],\n",
    "            \"image_urls\": hit[\"_source\"].get(\"image_urls\", \"\")\n",
    "        } for hit in hits\n",
    "    ]\n",
    "    return jsonify({\"results\": results})\n",
    "\n",
    "# I'll be using this to get image when result gives no image\n",
    "@app.route('/search_nearest_image', methods=['GET'])\n",
    "def search_nearest_image():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    \n",
    "    # Responds\n",
    "    query = request.args.get(\"query\", \"\")\n",
    "    cleaned_query = clean_text(query)\n",
    "    \n",
    "    res = es_client.search(index=index_name, body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    { \"match\": { \"name\": { \"query\": query, \"boost\": 3 } } },  # No stemming (Best match)\n",
    "                    { \"match\": { \"name.ngram\": { \"query\": query, \"boost\": 2 } } },  # Partial match with n-grams\n",
    "                    { \"match\": { \"stemmed_name\": { \"query\": cleaned_query, \"boost\": 2 } } },  # Stemmed query\n",
    "                    { \"match\": { \"search_text\": { \"query\": cleaned_query, \"fuzziness\": \"AUTO\", \"boost\": 1 } } }  # Stemmed + Fuzzy\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Get all hits\n",
    "    hits = res[\"hits\"][\"hits\"]\n",
    "    \n",
    "    # Iterate over hits to find the first result with an image\n",
    "    for hit in hits:\n",
    "        top_hit = hit[\"_source\"]\n",
    "        if \"image_urls\" in top_hit and top_hit[\"image_urls\"]:\n",
    "            result = {\n",
    "                \"recipe_id\": top_hit[\"recipe_id\"],\n",
    "                \"name\": top_hit[\"name\"],\n",
    "                \"image_urls\": top_hit[\"image_urls\"]\n",
    "            }\n",
    "            return jsonify({\"result\": result})\n",
    "    \n",
    "    # If no image was found\n",
    "    return jsonify({\"message\": \"No results with images found\"}), 404\n",
    "\n",
    "\n",
    "\n",
    "# UC-004: Detailed Dish Information\n",
    "@app.route('/recipe/<recipe_id>', methods=['GET'])\n",
    "def recipe_detail(recipe_id):\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    # Responds\n",
    "    res = es_client.get(index=index_name, id=recipe_id)\n",
    "    result = res[\"_source\"]\n",
    "    return jsonify(result)\n",
    "\n",
    "# UC-006: Bookmarking and Rating\n",
    "@app.route('/bookmark', methods=['POST'])\n",
    "def bookmark():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    data = request.get_json()\n",
    "    recipe_id = data.get(\"recipe_id\")\n",
    "    rating = data.get(\"rating\")\n",
    "    username = sessions.get(request.headers.get(\"Authorization\"), \"dev_user\")\n",
    "    user_bookmarks.setdefault(username, []).append({\"recipe_id\": recipe_id, \"rating\": rating})\n",
    "    return jsonify({\"message\": \"Bookmarked successfully\"})\n",
    "\n",
    "# UC-005: Folder Management\n",
    "@app.route('/folders', methods=['GET', 'POST'])\n",
    "def folders():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    username = sessions.get(request.headers.get(\"Authorization\"), \"dev_user\")\n",
    "    if request.method == 'GET':\n",
    "        return jsonify(user_folders.get(username, {}))\n",
    "    elif request.method == 'POST':\n",
    "        data = request.get_json()\n",
    "        folder_name = data.get(\"folder_name\")\n",
    "        user_folders.setdefault(username, {})[folder_name] = []\n",
    "        return jsonify({\"message\": f\"Folder '{folder_name}' created\"})\n",
    "\n",
    "# UC-007: Personalized Recommendations (dummy implementation)\n",
    "@app.route('/recommendations', methods=['GET'])\n",
    "def recommendations():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    res = es_client.search(index=index_name, body={\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"size\": 5\n",
    "    })\n",
    "    hits = res[\"hits\"][\"hits\"]\n",
    "    recs = [\n",
    "        {\n",
    "            \"recipe_id\": hit[\"_source\"][\"recipe_id\"],\n",
    "            \"name\": hit[\"_source\"][\"name\"],\n",
    "            \"snippet\": hit[\"_source\"][\"search_text\"][:150],\n",
    "            \"image_urls\": hit[\"_source\"].get(\"image_urls\", \"\")\n",
    "        } for hit in hits\n",
    "    ]\n",
    "    return jsonify({\"recommendations\": recs})\n",
    "\n",
    "print(\"Flask API endpoints defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Mar/2025 21:32:58] \"GET /recipe/69 HTTP/1.1\" 200 -\n",
      "[2025-03-06 21:33:23,045] ERROR in app: Exception on /recipe/10 [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\flask_cors\\extension.py\", line 194, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18048\\1505501164.py\", line 123, in recipe_detail\n",
      "    res = es_client.get(index=index_name, id=recipe_id)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py\", line 455, in wrapped\n",
      "    return api(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\_sync\\client\\__init__.py\", line 2049, in get\n",
      "    return self.perform_request(  # type: ignore[return-value]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py\", line 271, in perform_request\n",
      "    response = self._perform_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py\", line 352, in _perform_request\n",
      "    raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n",
      "elasticsearch.NotFoundError: NotFoundError(404, \"{'_index': 'recipes', '_id': '10', 'found': False}\")\n",
      "127.0.0.1 - - [06/Mar/2025 21:33:23] \"GET /recipe/10 HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [06/Mar/2025 21:33:26] \"GET /recipe/109 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2025 21:35:38] \"GET /recipe/109 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run the Flask app on port 5000\n",
    "app.run(port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Instructions\n",
    "\n",
    "1. **Authentication:** Use a REST client (or cURL) to POST to `/login` with JSON payload, e.g.: \n",
    "   ```json\n",
    "   {\"username\": \"user1\", \"password\": \"password1\"}\n",
    "   ```\n",
    "   You'll receive a token in the response. Use that token in the `Authorization` header for subsequent requests.\n",
    "\n",
    "2. **Search:** GET `/search?query=chicken` with the header `Authorization: <token>` to retrieve matching recipes.\n",
    "\n",
    "3. **Detailed View:** GET `/recipe/<recipe_id>` to fetch full details for a recipe.\n",
    "\n",
    "4. **Bookmarking:** POST to `/bookmark` with JSON payload containing a `recipe_id` and an optional `rating`.\n",
    "\n",
    "5. **Folder Management:** GET or POST to `/folders` to list or create folders.\n",
    "\n",
    "6. **Recommendations:** GET `/recommendations` to retrieve a list of recommended recipes (dummy implementation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE-IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
