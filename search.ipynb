{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe Search with BM25 and MongoDB\n",
    "\n",
    "This notebook connects to MongoDB to load recipe data, builds a BM25 index on the combined recipe fields (title, ingredients, and instructions), and sets up a Flask API for searching recipes and providing recommendations. The recommendation system tracks user search tags and uses the most frequent ones to drive the suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to MongoDB and Load Recipes\n",
    "\n",
    "This section connects to the local MongoDB instance and loads all recipes from the 'recipes' collection in the 'food_recipes' database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d8bdbce-7e6a-48f9-a8c1-2a3559e58b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1567551 recipes from MongoDB.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB (ensure mongod is running)\n",
    "client = MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "db = client['food_recipes']\n",
    "\n",
    "# Load recipes from MongoDB\n",
    "batch_size = 1000\n",
    "recipes_collection = db['recipes']\n",
    "cursor = recipes_collection.find({}).batch_size(batch_size)\n",
    "recipes = []\n",
    "\n",
    "for batch in cursor:\n",
    "    recipes.append(batch)\n",
    "\n",
    "print(f\"Loaded {len(recipes)} recipes from MongoDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download NLTK Data\n",
    "\n",
    "NLTK is used for tokenizing text. This cell downloads the necessary data (if not already present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40bdb96-39d7-4e33-bb3c-ff2ac4c24a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the BM25 Class\n",
    "\n",
    "The BM25 class builds an inverted index for a list of text documents and computes BM25 scores. These scores are later used to rank recipes based on the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d0d6ef-2129-41a4-b146-259086ea7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, documents, k1=1.5, b=0.75):\n",
    "        self.documents = documents  # list of text documents\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.N = len(documents)\n",
    "        self.doc_lengths = []\n",
    "        self.avg_doc_length = 0\n",
    "        self.index = defaultdict(list)  # mapping word -> list of (doc_index, term_frequency)\n",
    "        self.idf = {}\n",
    "\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        \"\"\"Build the inverted index and compute IDF values.\"\"\"\n",
    "        doc_freqs = defaultdict(int)\n",
    "        total_length = 0\n",
    "\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            words = word_tokenize(doc.lower())\n",
    "            self.doc_lengths.append(len(words))\n",
    "            total_length += len(words)\n",
    "            word_counts = defaultdict(int)\n",
    "            for word in words:\n",
    "                word_counts[word] += 1\n",
    "            for word, tf in word_counts.items():\n",
    "                doc_freqs[word] += 1\n",
    "                self.index[word].append((i, tf))\n",
    "\n",
    "        self.avg_doc_length = total_length / self.N if self.N > 0 else 0\n",
    "\n",
    "        for word, df in doc_freqs.items():\n",
    "            self.idf[word] = math.log((self.N - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "    def search(self, query, top_n=5):\n",
    "        \"\"\"Score the documents given a query and return the top_n document indices and scores.\"\"\"\n",
    "        query_words = word_tokenize(query.lower())\n",
    "        scores = defaultdict(float)\n",
    "\n",
    "        for word in query_words:\n",
    "            if word not in self.index:\n",
    "                continue\n",
    "\n",
    "            idf = self.idf.get(word, 0)\n",
    "            for doc_id, tf in self.index[word]:\n",
    "                dl = self.doc_lengths[doc_id]\n",
    "                score = idf * ((tf * (self.k1 + 1)) /\n",
    "                               (tf + self.k1 * (1 - self.b + self.b * (dl / self.avg_doc_length))))\n",
    "                scores[doc_id] += score\n",
    "\n",
    "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    def save(self, index_file=\"bm25_index.pkl\"):\n",
    "        import pickle\n",
    "        with open(index_file, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"index\": self.index,\n",
    "                \"doc_lengths\": self.doc_lengths,\n",
    "                \"avg_doc_length\": self.avg_doc_length,\n",
    "                \"idf\": self.idf,\n",
    "                \"N\": self.N,\n",
    "                \"documents\": self.documents,\n",
    "                \"k1\": self.k1,\n",
    "                \"b\": self.b,\n",
    "            }, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(index_file=\"bm25_index.pkl\"):\n",
    "        import pickle\n",
    "        with open(index_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        bm25 = BM25(data[\"documents\"], k1=data[\"k1\"], b=data[\"b\"])\n",
    "        bm25.index = data[\"index\"]\n",
    "        bm25.doc_lengths = data[\"doc_lengths\"]\n",
    "        bm25.avg_doc_length = data[\"avg_doc_length\"]\n",
    "        bm25.idf = data[\"idf\"]\n",
    "        bm25.N = data[\"N\"]\n",
    "        return bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build BM25 Documents\n",
    "\n",
    "We concatenate each recipe's title, ingredients, and instructions into one text document. This combined text is what the BM25 index will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa7b86-3a05-4d9f-93a4-100f3c3d4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "recipe_ids = []\n",
    "for recipe in recipes:\n",
    "    name = recipe.get('Name', '')\n",
    "    ingredients = ' '.join(recipe.get('RecipeIngredientParts', []))\n",
    "    instructions = ' '.join(recipe.get('RecipeInstructions', []))\n",
    "    text = \"{} {} {}\".format(name, ingredients, instructions)\n",
    "    documents.append(text)\n",
    "    recipe_ids.append(recipe.get('RecipeId'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the BM25 Index\n",
    "\n",
    "We create a BM25 index from the combined documents. This index is used later to score and rank recipes based on a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c0bf8-8de6-4a37-9fc8-7f5b21af2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 index built.\n"
     ]
    }
   ],
   "source": [
    "bm25_index = BM25(documents)\n",
    "print(\"BM25 index built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define the Recipe Search Function\n",
    "\n",
    "This function takes a query, uses the BM25 index to get the best matching documents, maps these back to the full recipe data from MongoDB, and appends the BM25 score to each recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2cfb3-3e12-4e59-a254-dfe7a3b47ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_recipes(query, top_n=5):\n",
    "    \"\"\"Search for recipes using BM25 and return matching recipes with scores.\"\"\"\n",
    "    # Get BM25 results: a list of (document index, score) pairs\n",
    "    results = bm25_index.search(query, top_n=top_n)\n",
    "    \n",
    "    # Map BM25 results back to MongoDB _id along with scores\n",
    "    matched = [(recipe_ids[doc_idx], score) for doc_idx, score in results]\n",
    "    matched_ids = [m[0] for m in matched]\n",
    "    \n",
    "    # Retrieve the full recipe documents\n",
    "    matched_recipes = list(recipes_collection.find({\"_id\": {\"$in\": matched_ids}}))\n",
    "    \n",
    "    # Add the BM25 score to each retrieved recipe\n",
    "    for recipe in matched_recipes:\n",
    "        for rid, score in matched:\n",
    "            if recipe['_id'] == rid:\n",
    "                recipe['bm25_score'] = score\n",
    "                break\n",
    "    return matched_recipes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Search Function\n",
    "\n",
    "We run a test search using the query \"salt\" to see the top BM25-scored recipes along with their scores. A sample of the BM25 vocabulary tokens is printed for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd4746-bb73-4f86-8964-ecb14f0d2d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query 'salt':\n",
      "\n",
      "Sample BM25 vocabulary tokens: []\n"
     ]
    }
   ],
   "source": [
    "query = \"salt\"\n",
    "results = search_recipes(query, top_n=5)\n",
    "print(f\"Search results for query '{query}':\")\n",
    "for res in results:\n",
    "    title = res.get('Name', 'No Title')  # use 'Name' instead of 'title'\n",
    "    score = res.get('bm25_score', 0)\n",
    "    print(f\"{title} - BM25 Score: {score:.3f}\")\n",
    "\n",
    "# Debug: Print a sample of the BM25 vocabulary tokens\n",
    "print(\"\\nSample BM25 vocabulary tokens:\", list(bm25_index.idf.keys())[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Flask API for Recipe Search and Recommendations\n",
    "\n",
    "This section sets up a basic Flask API with two endpoints:\n",
    "\n",
    "- **/search**: Accepts a query and an optional user_id. It runs the BM25 search and updates an in-memory tag store based on the query.\n",
    "- **/recommendations**: Uses the tracked search tags for a user to build a query from their top tags and returns recommended recipes.\n",
    "\n",
    "A helper function `update_user_tags` tokenizes the query and updates the user's tag counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "flask-api-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/Mar/2025 15:45:43] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [01/Mar/2025 15:45:53] \"GET /search HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Mar/2025 15:45:58] \"GET /search?query=egg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# In-memory store for tracking user search tags\n",
    "user_tags = {}\n",
    "\n",
    "def update_user_tags(user_id, query):\n",
    "    # Tokenize the query and update tag counts for the user\n",
    "    tags = word_tokenize(query.lower())\n",
    "    if user_id not in user_tags:\n",
    "        user_tags[user_id] = {}\n",
    "    for tag in tags:\n",
    "        user_tags[user_id][tag] = user_tags[user_id].get(tag, 0) + 1\n",
    "\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    query = request.args.get('query', '')\n",
    "    user_id = request.args.get('user_id', 'anonymous')\n",
    "    update_user_tags(user_id, query)\n",
    "    results = search_recipes(query, top_n=5)\n",
    "    return jsonify(results)\n",
    "\n",
    "@app.route('/recommendations', methods=['GET'])\n",
    "def recommendations():\n",
    "    user_id = request.args.get('user_id', 'anonymous')\n",
    "    # Use the tracked tags to form a recommendation query\n",
    "    tags = user_tags.get(user_id, {})\n",
    "    if not tags:\n",
    "        return jsonify({\"message\": \"No search history available for recommendations.\"})\n",
    "    # Sort tags by frequency and take the top 3\n",
    "    sorted_tags = sorted(tags.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_tags = \" \".join([tag for tag, count in sorted_tags[:3]])\n",
    "    results = search_recipes(top_tags, top_n=5)\n",
    "    return jsonify(results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE-IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
