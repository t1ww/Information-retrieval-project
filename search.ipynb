{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Recipe Browser Project\n",
    "\n",
    "By `652115013 Narongchai Rongthong`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we load the data from parquet file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes data already loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check if recipes_df is already loaded\n",
    "if 'recipes_df' not in globals():\n",
    "    recipes_df = pd.read_parquet('resource/recipes.parquet')\n",
    "    print(f\"Loaded {len(recipes_df)} recipes.\")\n",
    "else:\n",
    "    print(\"Recipes data already loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"_Z9BSk2zcMuFD=-1LlAX\"),\n",
    "    ca_certs=\"~/http_ca.crt\"\n",
    ")\n",
    "\n",
    "if es_client.ping():\n",
    "    print(\"Connected to Elasticsearch\")\n",
    "else:\n",
    "    print(\"Elasticsearch connection failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can start indexing the data\n",
    "- applying fields we need\n",
    "    - id\n",
    "    - name\n",
    "    - ingredients\n",
    "    - instuctions\n",
    "\n",
    "For searching i want to join those together so its easier to find into `cleaned` \"search text\"\n",
    "\n",
    "along with extra cleaned name\n",
    "\n",
    "Through `stemming` and removing `stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Setup text cleaner\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Exclude specific stopwords\n",
    "important_stop_words =  {\"with\", \"and\"}\n",
    "custom_stopwords = set(stopwords.words('english')) - important_stop_words  \n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())  \n",
    "    filtered_tokens = [word for word in tokens if word not in custom_stopwords]  \n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]  \n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Additionally, since if we send very short query like `\"t\"` or `\"to\"` we'd get completely empty results\n",
    "instead we can make it try to show up something that matches their `ngrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18048\\3485630063.py:10: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=index_name, ignore=[400, 404])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index: recipes\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 175\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m doc\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Bulk index the sample documents\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[43mbulk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mes_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipes_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(recipes_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m recipes into Elasticsearch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:540\u001b[0m, in \u001b[0;36mbulk\u001b[1;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# make streaming_bulk yield successful results so we can count them\u001b[39;00m\n\u001b[0;32m    539\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myield_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ok, item \u001b[38;5;129;01min\u001b[39;00m streaming_bulk(\n\u001b[0;32m    541\u001b[0m     client, actions, ignore_status\u001b[38;5;241m=\u001b[39mignore_status, span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelpers.bulk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    542\u001b[0m ):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# go through request-response pairs and detect failures\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stats_only:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:435\u001b[0m, in \u001b[0;36mstreaming_bulk\u001b[1;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, retry_on_status, span_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m bulk_data: List[\n\u001b[0;32m    429\u001b[0m     Union[\n\u001b[0;32m    430\u001b[0m         Tuple[_TYPE_BULK_ACTION_HEADER],\n\u001b[0;32m    431\u001b[0m         Tuple[_TYPE_BULK_ACTION_HEADER, _TYPE_BULK_ACTION_BODY],\n\u001b[0;32m    432\u001b[0m     ]\n\u001b[0;32m    433\u001b[0m ]\n\u001b[0;32m    434\u001b[0m bulk_actions: List[\u001b[38;5;28mbytes\u001b[39m]\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bulk_data, bulk_actions \u001b[38;5;129;01min\u001b[39;00m _chunk_actions(\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mmap\u001b[39m(expand_action_callback, actions),\n\u001b[0;32m    437\u001b[0m     chunk_size,\n\u001b[0;32m    438\u001b[0m     max_chunk_bytes,\n\u001b[0;32m    439\u001b[0m     serializer,\n\u001b[0;32m    440\u001b[0m ):\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    442\u001b[0m         to_retry: List[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SE-IR\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:234\u001b[0m, in \u001b[0;36m_chunk_actions\u001b[1;34m(actions, chunk_size, max_chunk_bytes, serializer)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03mSplit actions into chunks by number or size, serialize them into strings in\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03mthe process.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m chunker \u001b[38;5;241m=\u001b[39m _ActionChunker(\n\u001b[0;32m    232\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, max_chunk_bytes\u001b[38;5;241m=\u001b[39mmax_chunk_bytes, serializer\u001b[38;5;241m=\u001b[39mserializer\n\u001b[0;32m    233\u001b[0m )\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, data \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m    235\u001b[0m     ret \u001b[38;5;241m=\u001b[39m chunker\u001b[38;5;241m.\u001b[39mfeed(action, data)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "Cell \u001b[1;32mIn[40], line 137\u001b[0m, in \u001b[0;36mgenerate_docs\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    135\u001b[0m recipe_servings \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecipeServings\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m    136\u001b[0m recipe_yield \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecipeYield\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m--> 137\u001b[0m search_text \u001b[38;5;241m=\u001b[39m clean_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([name, \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mingredients\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([instructions])]))\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Handle image_url field\u001b[39;00m\n\u001b[0;32m    140\u001b[0m image_urls \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "# Define index name and sample size for development\n",
    "index_name = \"recipes\"\n",
    "sample_size = 100  # Set the sample size for testing (adjust as needed)\n",
    "\n",
    "# Delete the index if it already exists\n",
    "es_client.indices.delete(index=index_name, ignore=[400, 404])\n",
    "\n",
    "# Create the index with a mapping that uses an English analyzer\n",
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"ngram_tokenizer\": {\n",
    "                    \"type\": \"ngram\",\n",
    "                    \"min_gram\": 2,  # Minimum length of n-grams\n",
    "                    \"max_gram\": 3,  # Maximum length of n-grams\n",
    "                    \"token_chars\": [\"letter\", \"digit\"]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\n",
    "                    \"type\": \"english\"\n",
    "                },\n",
    "                \"ngram_analyzer\": {  # Add a custom n-gram analyzer\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"ngram_tokenizer\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"recipe_id\": {\"type\": \"keyword\"},\n",
    "            \"name\": { \n",
    "                \"type\": \"text\", \n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": { \n",
    "                    \"ngram\": {  # Add an n-gram variant of the name field\n",
    "                        \"type\": \"text\", \n",
    "                        \"analyzer\": \"ngram_analyzer\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"cleaned_name\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"author_name\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"recipe_category\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"description\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"ingredients\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"instructions\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"keywords\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\",\n",
    "                \"fields\": {\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"search_text\": {\"type\": \"text\", \"analyzer\": \"english\"},\n",
    "            \"image_urls\": {\"type\": \"keyword\"},\n",
    "            # Time-related fields\n",
    "            \"cook_time\": {\"type\": \"text\"},\n",
    "            \"prep_time\": {\"type\": \"text\"},\n",
    "            \"total_time\": {\"type\": \"text\"},\n",
    "            # Nutritional content fields\n",
    "            \"calories\": {\"type\": \"float\"},\n",
    "            \"fat_content\": {\"type\": \"float\"},\n",
    "            \"cholesterol_content\": {\"type\": \"float\"},\n",
    "            \"carbohydrate_content\": {\"type\": \"float\"},\n",
    "            \"fiber_content\": {\"type\": \"float\"},\n",
    "            \"sugar_content\": {\"type\": \"float\"},\n",
    "            \"protein_content\": {\"type\": \"float\"},\n",
    "            \"recipe_servings\": {\"type\": \"float\"},\n",
    "            \"recipe_yield\": {\"type\": \"float\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the index\n",
    "es_client.indices.create(index=index_name, body=mapping)\n",
    "print(f\"Created index: {index_name}\")\n",
    "\n",
    "# Get a sample of the recipes for development (you can adjust sample size)\n",
    "recipes_sample = recipes_df.head(sample_size)\n",
    "\n",
    "# Prepare the documents for bulk indexing\n",
    "def generate_docs(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        # Main Information\n",
    "        recipe_id = str(int(float(row.get('RecipeId', idx))))  # Ensures it's always an integer string\n",
    "        name = row.get('Name', '')\n",
    "        cleaned_name = clean_text(name)\n",
    "        author_name = row.get('AuthorName', '')\n",
    "        recipe_category = row.get('RecipeCategory', '')\n",
    "        description = row.get('Description', '')\n",
    "        \n",
    "        # Join ingredients correctly: [\"ingredient\", \"quantity\"]\n",
    "        ingredients = list(zip(row.get('RecipeIngredientParts', []), row.get('RecipeIngredientQuantities', [])))\n",
    "        \n",
    "        # Format the ingredients into a string like \"ingredient quantity\"\n",
    "        formatted_ingredients = [\"{} {}\".format(ingredient, quantity) for ingredient, quantity in ingredients]\n",
    "        \n",
    "        instructions = row.get('RecipeInstructions', [])\n",
    "        # Join the instructions into a single string if it's a list\n",
    "        formatted_instructions = \" \".join(instructions)\n",
    "        \n",
    "        keywords = row.get('Keywords', [])\n",
    "        \n",
    "        # Time\n",
    "        cook_time = row.get('CookTime', '')\n",
    "        prep_time = row.get('PrepTime', '')\n",
    "        total_time = row.get('TotalTime', '')\n",
    "        \n",
    "        # Nutritional Contents\n",
    "        calories = row.get('Calories', 0.0)\n",
    "        fat_content = row.get('FatContent', 0.0)\n",
    "        cholesterol_content = row.get('CholesterolContent', 0.0)\n",
    "        carbohydrate_content = row.get('CarbohydrateContent', 0.0)\n",
    "        fiber_content = row.get('FiberContent', 0.0)\n",
    "        sugar_content = row.get('SugarContent', 0.0)\n",
    "        protein_content = row.get('ProteinContent', 0.0)\n",
    "        recipe_servings = row.get('RecipeServings', 0.0)\n",
    "        recipe_yield = row.get('RecipeYield', 0.0)\n",
    "        \n",
    "        # Creating a combined search_text field\n",
    "        search_text = clean_text(\" \".join([name, \" \".join(formatted_ingredients), formatted_instructions]))\n",
    "        \n",
    "        # Handle image_url field\n",
    "        image_urls = row.get('Images', [])\n",
    "\n",
    "        doc = {\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": recipe_id,\n",
    "            \"_source\": {\n",
    "                \"recipe_id\": recipe_id,\n",
    "                \"name\": name,\n",
    "                \"cleaned_name\": cleaned_name,\n",
    "                \"author_name\": author_name,\n",
    "                \"recipe_category\": recipe_category,\n",
    "                \"description\": description,\n",
    "                \"ingredients\": formatted_ingredients,  # Use formatted ingredients\n",
    "                \"instructions\": formatted_instructions,  # Use formatted instructions\n",
    "                \"keywords\": keywords,\n",
    "                \"search_text\": search_text,\n",
    "                \"image_urls\": image_urls,\n",
    "                \"cook_time\": cook_time,\n",
    "                \"prep_time\": prep_time,\n",
    "                \"total_time\": total_time,\n",
    "                \"calories\": calories,\n",
    "                \"fat_content\": fat_content,\n",
    "                \"cholesterol_content\": cholesterol_content,\n",
    "                \"carbohydrate_content\": carbohydrate_content,\n",
    "                \"fiber_content\": fiber_content,\n",
    "                \"sugar_content\": sugar_content,\n",
    "                \"protein_content\": protein_content,\n",
    "                \"recipe_servings\": recipe_servings,\n",
    "                \"recipe_yield\": recipe_yield\n",
    "            }\n",
    "        }\n",
    "        yield doc\n",
    "\n",
    "\n",
    "# Bulk index the sample documents\n",
    "bulk(es_client, generate_docs(recipes_sample))\n",
    "\n",
    "print(f\"Indexed {len(recipes_sample)} recipes into Elasticsearch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create user system for token and tracking for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dummy user authentication and storage.\n"
     ]
    }
   ],
   "source": [
    "# --- Dummy User & In-Memory Data for Auth, Bookmarks, and Folders ---\n",
    "\n",
    "# Dummy user database (for UC-001: Authentication)\n",
    "users = {\n",
    "    \"user1\": \"password1\",\n",
    "    \"user2\": \"password2\"\n",
    "}\n",
    "\n",
    "# In-memory storage\n",
    "sessions = {}  # token -> username\n",
    "user_bookmarks = {}  # username -> list of {recipe_id, rating}\n",
    "user_folders = {}   # username -> {folder_name: [recipe_ids]}\n",
    "\n",
    "import uuid\n",
    "\n",
    "def generate_token():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "print(\"Initialized dummy user authentication and storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create flask app to expose api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask API endpoints defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Flask API Endpoints ---\n",
    "from flask import Flask, request, jsonify\n",
    "import random\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, supports_credentials=True, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "# Development mode token (for easier development)\n",
    "DEV_TOKEN = \"dev\" \n",
    "\n",
    "def generate_token():\n",
    "    return str(random.randint(100000, 999999))\n",
    "\n",
    "# UC-001: User Authentication\n",
    "@app.route('/login', methods=['POST'])\n",
    "def login():\n",
    "    data = request.get_json()\n",
    "    username = data.get(\"username\")\n",
    "    password = data.get(\"password\")\n",
    "    if username in users and users[username] == password:\n",
    "        token = generate_token()\n",
    "        sessions[token] = username\n",
    "        return jsonify({\"message\": \"Login successful\", \"token\": token})\n",
    "    return jsonify({\"message\": \"Invalid credentials\"}), 401\n",
    "\n",
    "@app.route('/logout', methods=['POST'])\n",
    "def logout():\n",
    "    token = request.headers.get(\"Authorization\")\n",
    "    if token in sessions:\n",
    "        sessions.pop(token)\n",
    "        return jsonify({\"message\": \"Logout successful\"})\n",
    "    return jsonify({\"message\": \"Invalid token\"}), 401\n",
    "\n",
    "# Helper function to check authentication\n",
    "def is_authenticated(request):\n",
    "    token = request.headers.get(\"Authorization\")\n",
    "    return token == DEV_TOKEN or token in sessions\n",
    "\n",
    "# UC-002 & UC-003: Recipe Search Functionality & Display Results\n",
    "@app.route('/search', methods=['GET'])\n",
    "def search():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    \n",
    "    # Responds\n",
    "    query = request.args.get(\"query\", \"\")\n",
    "    cleaned_query = clean_text(query)\n",
    "    res = es_client.search(index=index_name, body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    { \"match\": { \"name\": { \"query\": query, \"boost\": 3 } } },  # No stemming (Best match)\n",
    "                    { \"match\": { \"name.ngram\": { \"query\": query, \"boost\": 2 } } },  # Partial match with n-grams\n",
    "                    { \"match\": { \"stemmed_name\": { \"query\": cleaned_query, \"boost\": 2 } } },  # Stemmed query\n",
    "                    { \"match\": { \"search_text\": { \"query\": cleaned_query, \"fuzziness\": \"AUTO\", \"boost\": 1 } } }  # Stemmed + Fuzzy\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    hits = res[\"hits\"][\"hits\"]\n",
    "    results = [\n",
    "        {\n",
    "            \"recipe_id\": hit[\"_source\"][\"recipe_id\"],\n",
    "            \"name\": hit[\"_source\"][\"name\"],\n",
    "            \"snippet\": hit[\"_source\"][\"instructions\"][:150],\n",
    "            \"image_urls\": hit[\"_source\"].get(\"image_urls\", \"\")\n",
    "        } for hit in hits\n",
    "    ]\n",
    "    return jsonify({\"results\": results})\n",
    "\n",
    "# I'll be using this to get image when result gives no image\n",
    "@app.route('/search_nearest_image', methods=['GET'])\n",
    "def search_nearest_image():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    \n",
    "    # Responds\n",
    "    query = request.args.get(\"query\", \"\")\n",
    "    cleaned_query = clean_text(query)\n",
    "    \n",
    "    res = es_client.search(index=index_name, body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    { \"match\": { \"name\": { \"query\": query, \"boost\": 3 } } },  # No stemming (Best match)\n",
    "                    { \"match\": { \"name.ngram\": { \"query\": query, \"boost\": 2 } } },  # Partial match with n-grams\n",
    "                    { \"match\": { \"stemmed_name\": { \"query\": cleaned_query, \"boost\": 2 } } },  # Stemmed query\n",
    "                    { \"match\": { \"search_text\": { \"query\": cleaned_query, \"fuzziness\": \"AUTO\", \"boost\": 1 } } }  # Stemmed + Fuzzy\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Get all hits\n",
    "    hits = res[\"hits\"][\"hits\"]\n",
    "    \n",
    "    # Iterate over hits to find the first result with an image\n",
    "    for hit in hits:\n",
    "        top_hit = hit[\"_source\"]\n",
    "        if \"image_urls\" in top_hit and top_hit[\"image_urls\"]:\n",
    "            result = {\n",
    "                \"recipe_id\": top_hit[\"recipe_id\"],\n",
    "                \"name\": top_hit[\"name\"],\n",
    "                \"image_urls\": top_hit[\"image_urls\"]\n",
    "            }\n",
    "            return jsonify({\"result\": result})\n",
    "    \n",
    "    # If no image was found\n",
    "    return jsonify({\"message\": \"No results with images found\"}), 404\n",
    "\n",
    "\n",
    "\n",
    "# UC-004: Detailed Dish Information\n",
    "@app.route('/recipe/<recipe_id>', methods=['GET'])\n",
    "def recipe_detail(recipe_id):\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    # Responds\n",
    "    res = es_client.get(index=index_name, id=recipe_id)\n",
    "    result = res[\"_source\"]\n",
    "    return jsonify(result)\n",
    "\n",
    "# UC-006: Bookmarking and Rating\n",
    "@app.route('/bookmark', methods=['POST'])\n",
    "def bookmark():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    data = request.get_json()\n",
    "    recipe_id = data.get(\"recipe_id\")\n",
    "    rating = data.get(\"rating\")\n",
    "    username = sessions.get(request.headers.get(\"Authorization\"), \"dev_user\")\n",
    "    user_bookmarks.setdefault(username, []).append({\"recipe_id\": recipe_id, \"rating\": rating})\n",
    "    return jsonify({\"message\": \"Bookmarked successfully\"})\n",
    "\n",
    "# UC-005: Folder Management\n",
    "@app.route('/folders', methods=['GET', 'POST'])\n",
    "def folders():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    username = sessions.get(request.headers.get(\"Authorization\"), \"dev_user\")\n",
    "    if request.method == 'GET':\n",
    "        return jsonify(user_folders.get(username, {}))\n",
    "    elif request.method == 'POST':\n",
    "        data = request.get_json()\n",
    "        folder_name = data.get(\"folder_name\")\n",
    "        user_folders.setdefault(username, {})[folder_name] = []\n",
    "        return jsonify({\"message\": f\"Folder '{folder_name}' created\"})\n",
    "\n",
    "# UC-007: Personalized Recommendations (dummy implementation)\n",
    "@app.route('/recommendations', methods=['GET'])\n",
    "def recommendations():\n",
    "    # Authorization\n",
    "    if not is_authenticated(request):\n",
    "        return jsonify({\"message\": \"Unauthorized\"}), 401\n",
    "    res = es_client.search(index=index_name, body={\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"size\": 5\n",
    "    })\n",
    "    hits = res[\"hits\"][\"hits\"]\n",
    "    recs = [\n",
    "        {\n",
    "            \"recipe_id\": hit[\"_source\"][\"recipe_id\"],\n",
    "            \"name\": hit[\"_source\"][\"name\"],\n",
    "            \"snippet\": hit[\"_source\"][\"search_text\"][:150],\n",
    "            \"image_urls\": hit[\"_source\"].get(\"image_urls\", \"\")\n",
    "        } for hit in hits\n",
    "    ]\n",
    "    return jsonify({\"recommendations\": recs})\n",
    "\n",
    "print(\"Flask API endpoints defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Mar/2025 20:57:53] \"GET /recipe/69 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2025 20:58:25] \"OPTIONS /recipe/42 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2025 20:58:25] \"GET /recipe/42 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run the Flask app on port 5000\n",
    "app.run(port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Instructions\n",
    "\n",
    "1. **Authentication:** Use a REST client (or cURL) to POST to `/login` with JSON payload, e.g.: \n",
    "   ```json\n",
    "   {\"username\": \"user1\", \"password\": \"password1\"}\n",
    "   ```\n",
    "   You'll receive a token in the response. Use that token in the `Authorization` header for subsequent requests.\n",
    "\n",
    "2. **Search:** GET `/search?query=chicken` with the header `Authorization: <token>` to retrieve matching recipes.\n",
    "\n",
    "3. **Detailed View:** GET `/recipe/<recipe_id>` to fetch full details for a recipe.\n",
    "\n",
    "4. **Bookmarking:** POST to `/bookmark` with JSON payload containing a `recipe_id` and an optional `rating`.\n",
    "\n",
    "5. **Folder Management:** GET or POST to `/folders` to list or create folders.\n",
    "\n",
    "6. **Recommendations:** GET `/recommendations` to retrieve a list of recommended recipes (dummy implementation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE-IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
